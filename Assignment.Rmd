---
title: "assignment"
author: "Yineng Chen"
date: "6/30/2020"
output: 
  html_document:
    keep_md: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(parallel)
library(doParallel)
library(e1071)
```

## Task

Using data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, create a model to predict how well a subject perform in weight lifting exercises.

### classification of performance

1. Exactly according to the specification (Class A)

2. Throwing the elbows to the front (Class B)

3. Lifting the dumbbell only halfway (Class C)

4. Lowering the dumbbell only halfway (Class D) 

5. Throwing the hips to the front (Class E)


## Data input

### Load Data

```{r load data, include=FALSE}
trainset = read_csv("./pml-training.csv")

quizset = read_csv("./pml-testing.csv")


dim(trainset)
dim(quizset)
```


### Data Cleaning

According to the codebook, the data set includes summary statistics calculated at a measurement boundary. These statistics containes high proportions of missing values and/or error values. Therefore, these statistics are not used in training, instead, only raw data from accelerometers are used. The summary statistics have names begin with "kurtosis_", "skewness_", "max_", "min_", "amplitude_", "var_", "avg_", and "stddev_". Variables that are not related to prediction are also removed including X1. user_name, num_window,new_window,timestamp.

```{r}
# deal with missing values
kname = grep("^(kurtosis_|skewness_|max_|min_|amplitude_|var_|avg_|stddev_)|window|X1|name|time",names(trainset))
trainset = trainset[,-kname]
dim(trainset)
names(trainset)
```


## Algorithm

### Slit the trainset into training set and testing set

```{r}
inTrain = createDataPartition(trainset$classe, p = 0.6, list = F)
training = trainset[inTrain,]
testing = trainset[-inTrain,]
dim(training)
dim(testing)
```


### Creat a random forest model with cross validation



```{r}
myModelFilename <- "myModel.RData"
if (!file.exists(myModelFilename)){
  set.seed(95014)

  cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
  registerDoParallel(cluster)
  getDoParWorkers()


  fitControl <- trainControl(method = "cv",
                           number = 5,
                           allowParallel = TRUE,
                           p = 0.6)


  model1 <- train(classe~.,
                  data = training,
                  metric = "Accuracy",
                  method = "rf",
                preProcess = c("center","scale"),
                 trControl = fitControl)

   save(model1, file = "myModel.RData")
  
  stopCluster(cluster)
  registerDoSEQ()
  
  
} else {
    load(file = myModelFilename, verbose = TRUE)
}

```

```{r}

print(model1, digits = 4)
```


## Predict

```{r}
pred <- predict(model1, newdata = testing)
length(pred)
length(testing$classe)
```

## Evaluation

```{r}
confusionMatrix(pred, as.factor(testing$classe))
```

## Final Model

```{r}
model1$finalModel
```


## Quiz

```{r}
print(predict(model1, newdata=quizset))
```

